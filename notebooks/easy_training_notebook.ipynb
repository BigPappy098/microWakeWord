{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy microWakeWord Training\n",
    "\n",
    "This notebook provides a simplified approach to training custom wake word models using microWakeWord. It's designed to be accessible to users with minimal machine learning experience while still producing high-quality models.\n",
    "\n",
    "## What You'll Need\n",
    "\n",
    "- Python 3.10 installed\n",
    "- A GPU is recommended for faster training (but not required)\n",
    "- Your desired wake word phrase (e.g., \"hey computer\")\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install microWakeWord and dependencies\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    # `pymicro-features` is installed from a fork to support building on macOS\n",
    "    !pip install 'git+https://github.com/puddly/pymicro-features@puddly/minimum-cpp-version'\n",
    "\n",
    "# `audio-metadata` is installed from a fork to unpin `attrs` from a version that breaks Jupyter\n",
    "!pip install 'git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f'\n",
    "\n",
    "# Install ipywidgets for interactive notebook elements\n",
    "!pip install ipywidgets\n",
    "\n",
    "!git clone https://github.com/BigPappy098/microWakeWord\n",
    "!pip install -e ./microWakeWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Choose Your Wake Word\n",
    "\n",
    "Choose a wake word phrase that you want to use. Good wake words typically have:\n",
    "- Multiple syllables (3-5 is ideal)\n",
    "- Distinctive sounds that don't commonly appear in everyday speech\n",
    "- Clear pronunciation\n",
    "\n",
    "Examples: \"hey computer\", \"jarvis\", \"alexa\", \"computer\"\n",
    "\n",
    "You can use phonetic spellings to improve recognition. For example, \"computer\" might be better as \"kuhm-pyoo-ter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your wake word here\n",
    "wake_word = \"hey_computer\"  # Use underscores instead of spaces\n",
    "\n",
    "# Listen to a sample of how it will sound\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import Audio\n",
    "\n",
    "if not os.path.exists(\"./piper-sample-generator\"):\n",
    "    !git clone https://github.com/rhasspy/piper-sample-generator\n",
    "    !wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
    "    !pip install torch torchaudio piper-phonemize-cross==1.2.1\n",
    "\n",
    "    if \"piper-sample-generator/\" not in sys.path:\n",
    "        sys.path.append(\"piper-sample-generator/\")\n",
    "\n",
    "!mkdir -p sample_test\n",
    "!python3 piper-sample-generator/generate_samples.py \"{wake_word}\" \\\n",
    "--max-samples 1 \\\n",
    "--batch-size 1 \\\n",
    "--output-dir sample_test\n",
    "\n",
    "Audio(\"sample_test/0.wav\", autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Choose Training Parameters\n",
    "\n",
    "Now, let's configure the training process based on your wake word and needs:\n",
    "\n",
    "1. **Wake Word Length**: Choose a preset based on the length of your wake word\n",
    "   - `short`: For 1-2 syllable wake words (e.g., \"jarvis\")\n",
    "   - `medium`: For 3-4 syllable wake words (e.g., \"hey computer\")\n",
    "   - `long`: For 5+ syllable wake words (e.g., \"hey google assistant\")\n",
    "\n",
    "2. **Augmentation Level**: Choose how much to vary the training samples\n",
    "   - `light`: Less variation, good for quiet environments\n",
    "   - `medium`: Balanced variation, good for most home environments\n",
    "   - `heavy`: High variation, good for noisy environments\n",
    "\n",
    "3. **Sample Count**: How many synthetic samples to generate\n",
    "   - 500-1000 is good for testing\n",
    "   - 2000-5000 is recommended for production models\n",
    "   \n",
    "4. **Batch Size**: Size of batches during training\n",
    "   - Larger values may train faster but require more memory\n",
    "   - Smaller values use less memory but may train slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training parameters\n",
    "preset = \"medium\"  # Choose from: \"short\", \"medium\", \"long\"\n",
    "augmentation_level = \"medium\"  # Choose from: \"light\", \"medium\", \"heavy\"\n",
    "samples_count = 1000  # Number of samples to generate\n",
    "batch_size = 128  # Batch size for training (larger values may be faster but require more memory)\n",
    "\n",
    "# Output directory\n",
    "output_dir = f\"trained_models/{wake_word}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Negative Samples\n",
    "\n",
    "To train a robust model, we need \"negative\" samples - audio that is NOT the wake word. These help the model learn what to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download negative datasets\n",
    "output_dir = './negative_datasets'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    link_root = \"https://huggingface.co/datasets/kahrendt/microwakeword/resolve/main/\"\n",
    "    filenames = ['dinner_party.zip', 'dinner_party_eval.zip', 'no_speech.zip', 'speech.zip']\n",
    "    for fname in filenames:\n",
    "        link = link_root + fname\n",
    "        zip_path = f\"negative_datasets/{fname}\"\n",
    "        !wget -O {zip_path} {link}\n",
    "        !unzip -q {zip_path} -d {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Your Model\n",
    "\n",
    "Now we'll use our simplified training interface to train the model. This process includes:\n",
    "1. Generating synthetic wake word samples\n",
    "2. Generating spectrograms from the samples\n",
    "3. Creating a training configuration\n",
    "4. Training the neural network\n",
    "5. Converting to a streaming TFLite model for deployment\n",
    "\n",
    "**Note:** If you encounter a shape mismatch error like \"Invalid input shape for input Tensor\", it means there's an issue with the spectrogram generation. The latest version of the code should handle this automatically by setting the correct spectrogram dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microwakeword.easy_train import WakeWordTrainer\n",
    "\n",
    "# Create trainer\n",
    "trainer = WakeWordTrainer(\n",
    "    wake_word=wake_word,\n",
    "    output_dir=\"trained_models\",\n",
    "    preset=preset,\n",
    "    augmentation_level=augmentation_level,\n",
    "    samples_count=samples_count,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Run the full training pipeline\n",
    "model_path = trainer.run_full_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Download Your Model\n",
    "\n",
    "Once training is complete, you can download your model for use with ESPHome or other compatible systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Path to the trained model\n",
    "model_file = os.path.join(f\"trained_models/{wake_word}/model/streaming_quantized.tflite\")\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    print(f\"Your model is ready! Click below to download:\")\n",
    "    display(FileLink(model_file))\n",
    "else:\n",
    "    print(f\"Model file not found at {model_file}. Check for errors in the training process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create a Model Manifest for ESPHome\n",
    "\n",
    "To use your model with ESPHome, you need to create a model manifest JSON file. Here's a template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a model manifest for ESPHome\n",
    "manifest = {\n",
    "    \"name\": wake_word,\n",
    "    \"version\": 2,\n",
    "    \"type\": \"micro_speech\",\n",
    "    \"description\": f\"Custom wake word model for '{wake_word}'\",\n",
    "    \"specs\": {\n",
    "        \"average_window_length\": 10,\n",
    "        \"detection_threshold\": 0.7,\n",
    "        \"suppression_ms\": 1000,\n",
    "        \"minimum_count\": 3,\n",
    "        \"sample_rate\": 16000,\n",
    "        \"vocabulary\": [\"_silence_\", \"_unknown_\", wake_word]\n",
    "    }\n",
    "}\n",
    "\n",
    "manifest_file = os.path.join(f\"trained_models/{wake_word}/model/manifest.json\")\n",
    "with open(manifest_file, 'w') as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(f\"Model manifest created at {manifest_file}\")\n",
    "display(FileLink(manifest_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting and Fine-Tuning\n",
    "\n",
    "If your model doesn't perform as expected, here are some tips:\n",
    "\n",
    "1. **False Positives** (activates too often):\n",
    "   - Increase the `negative_class_weight` in the advanced configuration\n",
    "   - Increase the `detection_threshold` in the manifest file\n",
    "   - Try a different phonetic spelling of your wake word\n",
    "\n",
    "2. **False Negatives** (doesn't activate when it should):\n",
    "   - Decrease the `negative_class_weight` in the advanced configuration\n",
    "   - Decrease the `detection_threshold` in the manifest file\n",
    "   - Generate more training samples\n",
    "   - Try a different phonetic spelling of your wake word\n",
    "\n",
    "3. **Advanced Configuration**:\n",
    "   - For more control, you can pass an `advanced_config` dictionary to the `WakeWordTrainer`\n",
    "\n",
    "```python\n",
    "advanced_config = {\n",
    "    \"training_steps\": [30000],  # Train for longer\n",
    "    \"negative_class_weight\": [30],  # Increase to reduce false positives\n",
    "    \"time_mask_max_size\": [10],  # Increase for more augmentation\n",
    "    \"freq_mask_max_size\": [10]   # Increase for more augmentation\n",
    "}\n",
    "\n",
    "trainer = WakeWordTrainer(\n",
    "    wake_word=wake_word,\n",
    "    output_dir=\"trained_models\",\n",
    "    preset=preset,\n",
    "    augmentation_level=augmentation_level,\n",
    "    samples_count=samples_count,\n",
    "    batch_size=batch_size,\n",
    "    advanced_config=advanced_config\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
