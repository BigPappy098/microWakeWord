{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11cNiLqvWC6"
   },
   "source": [
    "# \ud83c\udfaf Training a microWakeWord Model\n",
    "\n",
    "<div style=\"background-color: #f0f7fb; padding: 15px; border-radius: 10px; border-left: 5px solid #3498db; margin-bottom: 20px;\">\n",
    "    <h2 style=\"margin-top: 0; color: #3498db;\">Welcome to microWakeWord Training!</h2>\n",
    "    <p>This notebook guides you through training a custom wake word model using microWakeWord. It provides a <b>visual and interactive</b> approach while maintaining the powerful functionality of the basic training process.</p>\n",
    "    <p><b>Python 3.10</b> is recommended for the best experience.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #fff3cd; padding: 15px; border-radius: 10px; border-left: 5px solid #f0ad4e; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #8a6d3b;\">\u26a0\ufe0f Important Note</h3>\n",
    "    <p>The model generated will require experimentation to achieve good results. You may need to adjust various settings to get a model that:</p>\n",
    "    <ul>\n",
    "        <li>Reliably detects your wake word</li>\n",
    "        <li>Doesn't trigger falsely on similar sounds</li>\n",
    "        <li>Works well in your specific environment</li>\n",
    "    </ul>\n",
    "    <p>This notebook includes interactive elements to help you experiment with different settings!</p>\n",
    "</div>\n",
    "\n",
    "## \ud83d\udccb What You'll Learn\n",
    "\n",
    "1. How to set up the microWakeWord training environment\n",
    "2. How to generate and augment wake word samples\n",
    "3. How to train a custom wake word model\n",
    "4. How to evaluate and export your model for use on devices\n",
    "\n",
    "<div style=\"background-color: #dff0d8; padding: 15px; border-radius: 10px; border-left: 5px solid #5cb85c; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #3c763d;\">\ud83d\udca1 Pro Tip</h3>\n",
    "    <p>Training is <b>much faster</b> on a local GPU. Make sure you have the necessary dependencies installed for GPU acceleration.</p>\n",
    "</div>\n",
    "\n",
    "At the end of this notebook, you'll have a TFLite model file ready for deployment on ESPHome devices. For deployment instructions, see the [ESPHome documentation](https://esphome.io/components/micro_wake_word) and [model examples](https://github.com/esphome/micro-wake-word-models/tree/main/models/v2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFf6511E65ff"
   },
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Setup: Install microWakeWord and dependencies\n",
    "# This cell installs all necessary packages for training\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Display a progress message\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #f8f9fa; padding: 10px; border-radius: 5px;'>\"\n",
    "    \"<h3 style='margin-top: 0;'>\ud83d\udce6 Installing dependencies...</h3>\"\n",
    "    \"<p>This may take a few minutes. Please wait until completion.</p>\"\n",
    "    \"</div>\"\n",
    "))\n",
    "\n",
    "# Platform-specific installations\n",
    "if platform.system() == \"Darwin\":\n",
    "    # `pymicro-features` is installed from a fork to support building on macOS\n",
    "    !pip install 'git+https://github.com/puddly/pymicro-features@puddly/minimum-cpp-version'\n",
    "\n",
    "# `audio-metadata` is installed from a fork to unpin `attrs` from a version that breaks Jupyter\n",
    "!pip install 'git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f'\n",
    "\n",
    "# Install ipywidgets for interactive notebook elements\n",
    "!pip install ipywidgets tqdm matplotlib\n",
    "\n",
    "# Clone and install microWakeWord\n",
    "!git clone https://github.com/BigPappy098/microWakeWord\n",
    "!pip install -e ./microWakeWord\n",
    "\n",
    "# Display success message\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #dff0d8; padding: 10px; border-radius: 5px;'>\"\n",
    "    \"<h3 style='margin-top: 0; color: #3c763d;'>\u2705 Setup Complete!</h3>\"\n",
    "    \"<p>All dependencies have been installed successfully.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfa4 Step 1: Choose Your Wake Word\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">Selecting an Effective Wake Word</h3>\n",
    "    <p>A good wake word should be:</p>\n",
    "    <ul>\n",
    "        <li><b>Distinctive</b>: Unique sound patterns not common in everyday speech</li>\n",
    "        <li><b>Multi-syllabic</b>: 2-5 syllables work best (e.g., \"hey computer\", \"alexa\")</li>\n",
    "        <li><b>Clear pronunciation</b>: Avoid words that are difficult to pronounce consistently</li>\n",
    "    </ul>\n",
    "    <p>You can use phonetic spellings to improve recognition. For example, \"computer\" might be better as \"kuhm-pyoo-ter\".</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEluu7nL7ywd"
   },
   "outputs": [],
   "source": [
    "# \ud83c\udfa4 Set your wake word and generate a sample to verify\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Audio, display, HTML\n",
    "\n",
    "# Create an interactive text input for the wake word\n",
    "wake_word_input = widgets.Text(\n",
    "    value='hey_computer',\n",
    "    description='Wake Word:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Help text\n",
    "help_text = widgets.HTML(\n",
    "    value=\"<p style='color: #666; font-style: italic;'>Use underscores instead of spaces (e.g., 'hey_computer'). Try phonetic spellings for better results.</p>\"\n",
    ")\n",
    "\n",
    "# Display the input widget\n",
    "display(wake_word_input)\n",
    "display(help_text)\n",
    "\n",
    "# Function to generate and play a sample\n",
    "def generate_sample(button):\n",
    "    target_word = wake_word_input.value\n",
    "    \n",
    "    # Show progress\n",
    "    progress_output.value = \"<p>Setting up sample generator...</p>\"\n",
    "    \n",
    "    # Setup piper sample generator if not already done\n",
    "    if not os.path.exists(\"./piper-sample-generator\"):\n",
    "        if platform.system() == \"Darwin\":\n",
    "            !git clone -b mps-support https://github.com/kahrendt/piper-sample-generator\n",
    "        else:\n",
    "            !git clone https://github.com/rhasspy/piper-sample-generator\n",
    "\n",
    "        !wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
    "\n",
    "        # Install system dependencies\n",
    "        !pip install torch torchaudio piper-phonemize-cross==1.2.1\n",
    "\n",
    "        if \"piper-sample-generator/\" not in sys.path:\n",
    "            sys.path.append(\"piper-sample-generator/\")\n",
    "    \n",
    "    # Generate the sample\n",
    "    progress_output.value = f\"<p>Generating sample for '{target_word}'...</p>\"\n",
    "    \n",
    "    !python3 piper-sample-generator/generate_samples.py \"{target_word}\" \\\n",
    "    --max-samples 1 \\\n",
    "    --batch-size 1 \\\n",
    "    --output-dir generated_samples\n",
    "    \n",
    "    # Display the audio\n",
    "    progress_output.value = \"<p style='color: green;'>\u2705 Sample generated! Listen below:</p>\"\n",
    "    display(Audio(\"generated_samples/0.wav\", autoplay=True))\n",
    "\n",
    "# Create a button to generate the sample\n",
    "generate_button = widgets.Button(\n",
    "    description='Generate Sample',\n",
    "    button_style='info',\n",
    "    icon='microphone'\n",
    ")\n",
    "\n",
    "# Progress output\n",
    "progress_output = widgets.HTML(value=\"\")\n",
    "\n",
    "# Connect the button to the function\n",
    "generate_button.on_click(generate_sample)\n",
    "\n",
    "# Display the button\n",
    "display(generate_button)\n",
    "display(progress_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd0a Step 2: Generate Training Samples\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Training Samples</h3>\n",
    "    <p>To train a robust model, we need many examples of our wake word. The sample generator creates synthetic speech samples with different voices and variations.</p>\n",
    "    <p>You can adjust the number of samples and batch size below. More samples generally lead to better models but take longer to generate.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SvGtCCM9akR"
   },
   "outputs": [],
   "source": [
    "# \ud83d\udd0a Generate multiple wake word samples for training\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Create sliders for sample count and batch size\n",
    "sample_count_slider = widgets.IntSlider(\n",
    "    value=1000,\n",
    "    min=100,\n",
    "    max=5000,\n",
    "    step=100,\n",
    "    description='Sample Count:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "batch_size_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=10,\n",
    "    max=200,\n",
    "    step=10,\n",
    "    description='Batch Size:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the sliders\n",
    "display(sample_count_slider)\n",
    "display(batch_size_slider)\n",
    "\n",
    "# Function to generate samples\n",
    "def generate_samples(button):\n",
    "    target_word = wake_word_input.value\n",
    "    sample_count = sample_count_slider.value\n",
    "    batch_size = batch_size_slider.value\n",
    "    \n",
    "    # Show progress message\n",
    "    progress_output2.value = f\"<p>Generating {sample_count} samples with batch size {batch_size}...</p>\"\n",
    "    \n",
    "    # Generate the samples\n",
    "    !python3 piper-sample-generator/generate_samples.py \"{target_word}\" \\\n",
    "    --max-samples {sample_count} \\\n",
    "    --batch-size {batch_size} \\\n",
    "    --output-dir generated_samples\n",
    "    \n",
    "    # Count the generated files\n",
    "    import glob\n",
    "    file_count = len(glob.glob('generated_samples/*.wav'))\n",
    "    \n",
    "    # Display success message\n",
    "    progress_output2.value = f\"<p style='color: green;'>\u2705 Generated {file_count} samples successfully!</p>\"\n",
    "\n",
    "# Create a button to generate samples\n",
    "generate_samples_button = widgets.Button(\n",
    "    description='Generate Training Samples',\n",
    "    button_style='primary',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "# Progress output\n",
    "progress_output2 = widgets.HTML(value=\"\")\n",
    "\n",
    "# Connect the button to the function\n",
    "generate_samples_button.on_click(generate_samples)\n",
    "\n",
    "# Display the button\n",
    "display(generate_samples_button)\n",
    "display(progress_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce5 Step 3: Download Negative Samples\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Negative Samples</h3>\n",
    "    <p>To train a robust model, we need \"negative\" samples - audio that is NOT the wake word. These help the model learn what to ignore.</p>\n",
    "    <p>The pre-generated negative datasets include:</p>\n",
    "    <ul>\n",
    "        <li><b>Speech</b>: General speech samples</li>\n",
    "        <li><b>Dinner Party</b>: Conversational audio with multiple speakers</li>\n",
    "        <li><b>No Speech</b>: Environmental sounds without speech</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udce5 Download pre-generated negative datasets\n",
    "\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Create a progress output widget\n",
    "progress_output3 = widgets.HTML(value=\"\")\n",
    "display(progress_output3)\n",
    "\n",
    "# Function to download negative datasets\n",
    "def download_negative_datasets(button):\n",
    "    progress_output3.value = \"<p>Starting download of negative datasets...</p>\"\n",
    "    \n",
    "    output_dir = './negative_datasets'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        link_root = \"https://huggingface.co/datasets/kahrendt/microwakeword/resolve/main/\"\n",
    "        filenames = ['dinner_party.zip', 'dinner_party_eval.zip', 'no_speech.zip', 'speech.zip']\n",
    "        \n",
    "        for i, fname in enumerate(filenames):\n",
    "            progress_output3.value = f\"<p>Downloading {fname} ({i+1}/{len(filenames)})...</p>\"\n",
    "            link = link_root + fname\n",
    "            zip_path = f\"negative_datasets/{fname}\"\n",
    "            !wget -O {zip_path} {link}\n",
    "            \n",
    "            progress_output3.value = f\"<p>Extracting {fname}...</p>\"\n",
    "            !unzip -q {zip_path} -d {output_dir}\n",
    "    \n",
    "        progress_output3.value = \"<p style='color: green;'>\u2705 All negative datasets downloaded and extracted successfully!</p>\"\n",
    "    else:\n",
    "        progress_output3.value = \"<p style='color: blue;'>\u2139\ufe0f Negative datasets already exist. Skipping download.</p>\"\n",
    "\n",
    "# Create a button to download datasets\n",
    "download_button = widgets.Button(\n",
    "    description='Download Negative Datasets',\n",
    "    button_style='warning',\n",
    "    icon='download'\n",
    ")\n",
    "\n",
    "# Connect the button to the function\n",
    "download_button.on_click(download_negative_datasets)\n",
    "\n",
    "# Display the button\n",
    "display(download_button)\n",
    "\n",
    "# Add a note about the datasets\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> This download may take several minutes depending on your internet connection. \"\n",
    "    \"The total size is approximately 500MB.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd04 Step 4: Set Up Audio Augmentation\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Audio Augmentation</h3>\n",
    "    <p>Audio augmentation helps create more robust models by applying various transformations to our samples:</p>\n",
    "    <ul>\n",
    "        <li><b>Background Noise</b>: Adds realistic background sounds</li>\n",
    "        <li><b>Room Effects</b>: Simulates different acoustic environments</li>\n",
    "        <li><b>Audio Effects</b>: Applies distortion, EQ, and other modifications</li>\n",
    "    </ul>\n",
    "    <p>You can adjust the intensity of these effects using the controls below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd04 Configure audio augmentation settings\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Create sliders for augmentation parameters\n",
    "background_prob_slider = widgets.FloatSlider(\n",
    "    value=0.75,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Background Noise:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "rir_prob_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Room Effects:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "effects_prob_slider = widgets.FloatSlider(\n",
    "    value=0.1,\n",
    "    min=0.0,\n",
    "    max=0.5,\n",
    "    step=0.05,\n",
    "    description='Audio Effects:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "snr_range_slider = widgets.IntRangeSlider(\n",
    "    value=[-5, 10],\n",
    "    min=-20,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='SNR Range (dB):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the sliders\n",
    "display(HTML(\"<h4>Augmentation Intensity Controls</h4>\"))\n",
    "display(background_prob_slider)\n",
    "display(rir_prob_slider)\n",
    "display(effects_prob_slider)\n",
    "display(snr_range_slider)\n",
    "\n",
    "# Function to set up augmentation\n",
    "def setup_augmentation(button):\n",
    "    from microwakeword.audio.augmentation import Augmentation\n",
    "    from microwakeword.audio.clips import Clips\n",
    "    \n",
    "    progress_output4.value = \"<p>Setting up audio augmentation...</p>\"\n",
    "    \n",
    "    # Get values from sliders\n",
    "    bg_prob = background_prob_slider.value\n",
    "    rir_prob = rir_prob_slider.value\n",
    "    effect_prob = effects_prob_slider.value\n",
    "    min_snr, max_snr = snr_range_slider.value\n",
    "    \n",
    "    # Set up clips and augmentation\n",
    "    global clips, augmenter\n",
    "    \n",
    "    clips = Clips(input_directory='generated_samples',\n",
    "                  file_pattern='*.wav',\n",
    "                  max_clip_duration_s=None,\n",
    "                  remove_silence=False,\n",
    "                  random_split_seed=10,\n",
    "                  split_count=0.1,\n",
    "                  )\n",
    "    \n",
    "    augmenter = Augmentation(augmentation_duration_s=3.2,\n",
    "                             augmentation_probabilities = {\n",
    "                                    \"SevenBandParametricEQ\": effect_prob,\n",
    "                                    \"TanhDistortion\": effect_prob,\n",
    "                                    \"PitchShift\": effect_prob,\n",
    "                                    \"BandStopFilter\": effect_prob,\n",
    "                                    \"AddColorNoise\": effect_prob,\n",
    "                                    \"AddBackgroundNoise\": bg_prob,\n",
    "                                    \"Gain\": 1.0,\n",
    "                                    \"RIR\": rir_prob,\n",
    "                                },\n",
    "                             impulse_paths = ['mit_rirs'],\n",
    "                             background_paths = ['fma_16k', 'audioset_16k'],\n",
    "                             background_min_snr_db = min_snr,\n",
    "                             background_max_snr_db = max_snr,\n",
    "                             min_jitter_s = 0.195,\n",
    "                             max_jitter_s = 0.205,\n",
    "                             )\n",
    "    \n",
    "    progress_output4.value = \"<p style='color: green;'>\u2705 Audio augmentation configured successfully!</p>\"\n",
    "    \n",
    "    # Enable the preview button\n",
    "    preview_button.disabled = False\n",
    "\n",
    "# Function to preview augmentation\n",
    "def preview_augmentation(button):\n",
    "    from IPython.display import Audio\n",
    "    from microwakeword.audio.audio_utils import save_clip\n",
    "    \n",
    "    progress_output4.value = \"<p>Generating augmented preview...</p>\"\n",
    "    \n",
    "    # Get a random clip and augment it\n",
    "    random_clip = clips.get_random_clip()\n",
    "    augmented_clip = augmenter.augment_clip(random_clip)\n",
    "    save_clip(augmented_clip, 'augmented_preview.wav')\n",
    "    \n",
    "    progress_output4.value = \"<p style='color: green;'>\u2705 Preview generated! Listen below:</p>\"\n",
    "    display(Audio(\"augmented_preview.wav\", autoplay=True))\n",
    "\n",
    "# Create buttons\n",
    "setup_button = widgets.Button(\n",
    "    description='Setup Augmentation',\n",
    "    button_style='info',\n",
    "    icon='cog'\n",
    ")\n",
    "\n",
    "preview_button = widgets.Button(\n",
    "    description='Preview Augmentation',\n",
    "    button_style='success',\n",
    "    icon='headphones',\n",
    "    disabled=True  # Initially disabled until setup is complete\n",
    ")\n",
    "\n",
    "# Progress output\n",
    "progress_output4 = widgets.HTML(value=\"\")\n",
    "\n",
    "# Connect buttons to functions\n",
    "setup_button.on_click(setup_augmentation)\n",
    "preview_button.on_click(preview_augmentation)\n",
    "\n",
    "# Display buttons\n",
    "button_box = widgets.HBox([setup_button, preview_button])\n",
    "display(button_box)\n",
    "display(progress_output4)\n",
    "\n",
    "# Add a note about augmentation\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #dff0d8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Tip:</b> Experiment with different augmentation settings to improve model robustness. \"\n",
    "    \"Higher values create more challenging training data but may make training more difficult.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Step 5: Generate Augmented Features\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Feature Generation</h3>\n",
    "    <p>In this step, we'll generate spectrograms from our augmented audio samples. These spectrograms will be used to train the neural network.</p>\n",
    "    <p>We'll create three sets of data:</p>\n",
    "    <ul>\n",
    "        <li><b>Training</b>: Used to train the model</li>\n",
    "        <li><b>Validation</b>: Used to evaluate the model during training</li>\n",
    "        <li><b>Testing</b>: Used for final evaluation</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Generate augmented features for training, validation, and testing\n",
    "\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Progress output\n",
    "progress_output5 = widgets.HTML(value=\"\")\n",
    "\n",
    "# Function to generate features\n",
    "def generate_features(button):\n",
    "    from microwakeword.audio.spectrograms import SpectrogramGeneration\n",
    "    from mmap_ninja.ragged import RaggedMmap\n",
    "    \n",
    "    progress_output5.value = \"<p>Starting feature generation...</p>\"\n",
    "    \n",
    "    output_dir = 'generated_augmented_features'\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    \n",
    "    splits = [\"training\", \"validation\", \"testing\"]\n",
    "    for i, split in enumerate(splits):\n",
    "        progress_output5.value = f\"<p>Processing {split} set ({i+1}/{len(splits)})...</p>\"\n",
    "        \n",
    "        out_dir = os.path.join(output_dir, split)\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        \n",
    "        split_name = \"train\"\n",
    "        repetition = 2\n",
    "        \n",
    "        spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                           augmenter=augmenter,\n",
    "                                           slide_frames=10,\n",
    "                                           step_ms=10,\n",
    "                                           )\n",
    "        \n",
    "        if split == \"validation\":\n",
    "            split_name = \"validation\"\n",
    "            repetition = 1\n",
    "        elif split == \"testing\":\n",
    "            split_name = \"test\"\n",
    "            repetition = 1\n",
    "            spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                               augmenter=augmenter,\n",
    "                                               slide_frames=1,\n",
    "                                               step_ms=10,\n",
    "                                               )\n",
    "        \n",
    "        progress_output5.value = f\"<p>Generating spectrograms for {split} set...</p>\"\n",
    "        \n",
    "        RaggedMmap.from_generator(\n",
    "            out_dir=os.path.join(out_dir, 'wakeword_mmap'),\n",
    "            sample_generator=spectrograms.spectrogram_generator(split=split_name, repeat=repetition),\n",
    "            batch_size=100,\n",
    "            verbose=True,\n",
    "        )\n",
    "    \n",
    "    progress_output5.value = \"<p style='color: green;'>\u2705 All features generated successfully!</p>\"\n",
    "    \n",
    "    # Enable the next button\n",
    "    config_button.disabled = False\n",
    "\n",
    "# Create a button to generate features\n",
    "generate_features_button = widgets.Button(\n",
    "    description='Generate Features',\n",
    "    button_style='primary',\n",
    "    icon='cogs'\n",
    ")\n",
    "\n",
    "# Create a button for the next step (initially disabled)\n",
    "config_button = widgets.Button(\n",
    "    description='Continue to Training Config',\n",
    "    button_style='success',\n",
    "    icon='arrow-right',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "# Connect buttons to functions\n",
    "generate_features_button.on_click(generate_features)\n",
    "\n",
    "# Display buttons\n",
    "button_box = widgets.HBox([generate_features_button, config_button])\n",
    "display(button_box)\n",
    "display(progress_output5)\n",
    "\n",
    "# Add a note about feature generation\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Feature generation may take several minutes depending on your hardware. \"\n",
    "    \"This process converts audio samples into spectrograms that the neural network can process.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u2699\ufe0f Step 6: Configure Training Parameters\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Training Configuration</h3>\n",
    "    <p>The training configuration controls how the model learns from our data. Key parameters include:</p>\n",
    "    <ul>\n",
    "        <li><b>Training Steps</b>: How long to train the model</li>\n",
    "        <li><b>Batch Size</b>: How many samples to process at once</li>\n",
    "        <li><b>Class Weights</b>: How to balance positive and negative examples</li>\n",
    "        <li><b>Learning Rate</b>: How quickly the model adapts to the training data</li>\n",
    "    </ul>\n",
    "    <p>Adjust these parameters to find the optimal balance for your wake word.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2699\ufe0f Configure training parameters\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Create sliders for training parameters\n",
    "training_steps_slider = widgets.IntSlider(\n",
    "    value=10000,\n",
    "    min=5000,\n",
    "    max=30000,\n",
    "    step=1000,\n",
    "    description='Training Steps:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "batch_size_slider = widgets.IntSlider(\n",
    "    value=128,\n",
    "    min=32,\n",
    "    max=256,\n",
    "    step=32,\n",
    "    description='Batch Size:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "negative_weight_slider = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=5,\n",
    "    max=50,\n",
    "    step=5,\n",
    "    description='Negative Class Weight:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "learning_rate_slider = widgets.FloatLogSlider(\n",
    "    value=0.001,\n",
    "    base=10,\n",
    "    min=-4,  # 10^-4 = 0.0001\n",
    "    max=-2,  # 10^-2 = 0.01\n",
    "    step=0.1,\n",
    "    description='Learning Rate:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the sliders\n",
    "display(HTML(\"<h4>Training Parameters</h4>\"))\n",
    "display(training_steps_slider)\n",
    "display(batch_size_slider)\n",
    "display(negative_weight_slider)\n",
    "display(learning_rate_slider)\n",
    "\n",
    "# Progress output\n",
    "progress_output6 = widgets.HTML(value=\"\")\n",
    "\n",
    "# Function to create training configuration\n",
    "def create_config(button):\n",
    "    progress_output6.value = \"<p>Creating training configuration...</p>\"\n",
    "    \n",
    "    # Get values from sliders\n",
    "    training_steps = training_steps_slider.value\n",
    "    batch_size = batch_size_slider.value\n",
    "    negative_weight = negative_weight_slider.value\n",
    "    learning_rate = learning_rate_slider.value\n",
    "    \n",
    "    # Create configuration dictionary\n",
    "    config = {}\n",
    "    \n",
    "    config[\"window_step_ms\"] = 10\n",
    "    config[\"train_dir\"] = \"trained_models/wakeword\"\n",
    "    \n",
    "    # Configure feature directories\n",
    "    config[\"features\"] = [\n",
    "        {\n",
    "            \"features_dir\": \"generated_augmented_features\",\n",
    "            \"sampling_weight\": 2.0,\n",
    "            \"penalty_weight\": 1.0,\n",
    "            \"truth\": True,\n",
    "            \"truncation_strategy\": \"truncate_start\",\n",
    "            \"type\": \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            \"features_dir\": \"negative_datasets/speech\",\n",
    "            \"sampling_weight\": 10.0,\n",
    "            \"penalty_weight\": 1.0,\n",
    "            \"truth\": False,\n",
    "            \"truncation_strategy\": \"random\",\n",
    "            \"type\": \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            \"features_dir\": \"negative_datasets/dinner_party\",\n",
    "            \"sampling_weight\": 10.0,\n",
    "            \"penalty_weight\": 1.0,\n",
    "            \"truth\": False,\n",
    "            \"truncation_strategy\": \"random\",\n",
    "            \"type\": \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            \"features_dir\": \"negative_datasets/no_speech\",\n",
    "            \"sampling_weight\": 5.0,\n",
    "            \"penalty_weight\": 1.0,\n",
    "            \"truth\": False,\n",
    "            \"truncation_strategy\": \"random\",\n",
    "            \"type\": \"mmap\",\n",
    "        },\n",
    "        { # Only used for validation and testing\n",
    "            \"features_dir\": \"negative_datasets/dinner_party_eval\",\n",
    "            \"sampling_weight\": 0.0,\n",
    "            \"penalty_weight\": 1.0,\n",
    "            \"truth\": False,\n",
    "            \"truncation_strategy\": \"split\",\n",
    "            \"type\": \"mmap\",\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Training parameters\n",
    "    config[\"training_steps\"] = [training_steps]\n",
    "    config[\"positive_class_weight\"] = [1]\n",
    "    config[\"negative_class_weight\"] = [negative_weight]\n",
    "    config[\"learning_rates\"] = [learning_rate]\n",
    "    config[\"batch_size\"] = batch_size\n",
    "    \n",
    "    # SpecAugment parameters (disabled by default)\n",
    "    config[\"time_mask_max_size\"] = [0]\n",
    "    config[\"time_mask_count\"] = [0]\n",
    "    config[\"freq_mask_max_size\"] = [0]\n",
    "    config[\"freq_mask_count\"] = [0]\n",
    "    \n",
    "    # Evaluation parameters\n",
    "    config[\"eval_step_interval\"] = 500\n",
    "    config[\"clip_duration_ms\"] = 1500\n",
    "    \n",
    "    # Model selection criteria\n",
    "    config[\"target_minimization\"] = 0.9\n",
    "    config[\"minimization_metric\"] = None\n",
    "    config[\"maximization_metric\"] = \"average_viable_recall\"\n",
    "    \n",
    "    # Save configuration to file\n",
    "    with open(os.path.join(\"training_parameters.yaml\"), \"w\") as file:\n",
    "        yaml.dump(config, file)\n",
    "    \n",
    "    progress_output6.value = \"<p style='color: green;'>\u2705 Training configuration created successfully!</p>\"\n",
    "    \n",
    "    # Enable the train button\n",
    "    train_button.disabled = False\n",
    "\n",
    "# Create buttons\n",
    "create_config_button = widgets.Button(\n",
    "    description='Create Configuration',\n",
    "    button_style='info',\n",
    "    icon='file-code'\n",
    ")\n",
    "\n",
    "train_button = widgets.Button(\n",
    "    description='Continue to Training',\n",
    "    button_style='success',\n",
    "    icon='arrow-right',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "# Connect buttons to functions\n",
    "create_config_button.on_click(create_config)\n",
    "\n",
    "# Display buttons\n",
    "button_box = widgets.HBox([create_config_button, train_button])\n",
    "display(button_box)\n",
    "display(progress_output6)\n",
    "\n",
    "# Add a note about configuration\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #dff0d8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Tip:</b> For most wake words, the default settings work well as a starting point. \"\n",
    "    \"If your model doesn't perform well, try adjusting these parameters:</p>\"\n",
    "    \"<ul>\"\n",
    "    \"<li>Increase <b>Training Steps</b> for better accuracy (but longer training time)</li>\"\n",
    "    \"<li>Increase <b>Negative Class Weight</b> to reduce false positives</li>\"\n",
    "    \"<li>Decrease <b>Negative Class Weight</b> if the model rarely detects the wake word</li>\"\n",
    "    \"</ul>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Step 7: Train the Model\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Model Training</h3>\n",
    "    <p>Now we'll train the neural network model using the configuration we created. The training process:</p>\n",
    "    <ul>\n",
    "        <li>Feeds batches of spectrograms to the neural network</li>\n",
    "        <li>Adjusts the model weights based on prediction errors</li>\n",
    "        <li>Periodically evaluates the model on validation data</li>\n",
    "        <li>Saves the best-performing model weights</li>\n",
    "    </ul>\n",
    "    <p>Training may take several minutes to hours depending on your hardware and the number of training steps.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\ude80 Train the wake word model\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create model architecture selection dropdown\n",
    "model_architecture = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('MixedNet (Recommended)', 'mixednet'),\n",
    "        ('MobileNet', 'mobilenet'),\n",
    "        ('ResNet', 'resnet')\n",
    "    ],\n",
    "    value='mixednet',\n",
    "    description='Model Architecture:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Create model size selection dropdown\n",
    "model_size = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Small', 'small'),\n",
    "        ('Medium (Recommended)', 'medium'),\n",
    "        ('Large', 'large')\n",
    "    ],\n",
    "    value='medium',\n",
    "    description='Model Size:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the dropdowns\n",
    "display(HTML(\"<h4>Model Architecture Settings</h4>\"))\n",
    "display(model_architecture)\n",
    "display(model_size)\n",
    "\n",
    "# Progress output\n",
    "progress_output7 = widgets.HTML(value=\"\")\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(button):\n",
    "    import subprocess\n",
    "    import os\n",
    "    import time\n",
    "    \n",
    "    progress_output7.value = \"<p>Starting model training...</p>\"\n",
    "    \n",
    "    # Get selected architecture and size\n",
    "    arch = model_architecture.value\n",
    "    size = model_size.value\n",
    "    \n",
    "    # Define architecture parameters based on size\n",
    "    if arch == 'mixednet':\n",
    "        if size == 'small':\n",
    "            pointwise_filters = \"48,48,48,48\"\n",
    "            kernel_sizes = \"'[5],[7,11],[9,15],[17]'\"\n",
    "            first_conv_filters = 24\n",
    "        elif size == 'medium':\n",
    "            pointwise_filters = \"64,64,64,64\"\n",
    "            kernel_sizes = \"'[5],[7,11],[9,15],[23]'\"\n",
    "            first_conv_filters = 32\n",
    "        else:  # large\n",
    "            pointwise_filters = \"96,96,96,96\"\n",
    "            kernel_sizes = \"'[5],[7,11],[9,15],[23]'\"\n",
    "            first_conv_filters = 48\n",
    "            \n",
    "        # Build the command\n",
    "        cmd = f\"python -m microwakeword.model_train_eval \\\n",
    "        --training_config='training_parameters.yaml' \\\n",
    "        --train 1 \\\n",
    "        --restore_checkpoint 1 \\\n",
    "        --test_tf_nonstreaming 0 \\\n",
    "        --test_tflite_nonstreaming 0 \\\n",
    "        --test_tflite_nonstreaming_quantized 0 \\\n",
    "        --test_tflite_streaming 0 \\\n",
    "        --test_tflite_streaming_quantized 1 \\\n",
    "        --use_weights \\\"best_weights\\\" \\\n",
    "        mixednet \\\n",
    "        --pointwise_filters \\\"{pointwise_filters}\\\" \\\n",
    "        --repeat_in_block \\\"1,1,1,1\\\" \\\n",
    "        --mixconv_kernel_sizes {kernel_sizes} \\\n",
    "        --residual_connection \\\"0,0,0,0\\\" \\\n",
    "        --first_conv_filters {first_conv_filters} \\\n",
    "        --first_conv_kernel_size 5 \\\n",
    "        --stride 3\"\n",
    "    else:\n",
    "        # Simplified command for other architectures\n",
    "        cmd = f\"python -m microwakeword.model_train_eval \\\n",
    "        --training_config='training_parameters.yaml' \\\n",
    "        --train 1 \\\n",
    "        --restore_checkpoint 1 \\\n",
    "        --test_tf_nonstreaming 0 \\\n",
    "        --test_tflite_nonstreaming 0 \\\n",
    "        --test_tflite_nonstreaming_quantized 0 \\\n",
    "        --test_tflite_streaming 0 \\\n",
    "        --test_tflite_streaming_quantized 1 \\\n",
    "        --use_weights \\\"best_weights\\\" \\\n",
    "        {arch}\"\n",
    "    \n",
    "    # Update progress\n",
    "    progress_output7.value = f\"<p>Training model with {arch} architecture ({size} size)...</p>\"\n",
    "    progress_output7.value += \"<p>This may take a while. Please be patient.</p>\"\n",
    "    \n",
    "    # Run the command\n",
    "    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "    \n",
    "    # Create a progress bar\n",
    "    progress_bar = widgets.IntProgress(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=100,\n",
    "        description='Training:',\n",
    "        bar_style='info',\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "    display(progress_bar)\n",
    "    \n",
    "    # Process output\n",
    "    output_text = widgets.Output()\n",
    "    display(output_text)\n",
    "    \n",
    "    with output_text:\n",
    "        for line in process.stdout:\n",
    "            print(line.strip())\n",
    "            if \"step\" in line and \"loss\" in line:\n",
    "                try:\n",
    "                    # Extract step number and update progress\n",
    "                    step_str = line.split(\"step\")[1].split(\",\")[0].strip()\n",
    "                    step = int(step_str)\n",
    "                    training_steps = training_steps_slider.value\n",
    "                    progress = min(100, int(step * 100 / training_steps))\n",
    "                    progress_bar.value = progress\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Wait for process to complete\n",
    "    process.wait()\n",
    "    \n",
    "    if process.returncode == 0:\n",
    "        progress_output7.value = \"<p style='color: green;'>\u2705 Model training completed successfully!</p>\"\n",
    "        # Enable the export button\n",
    "        export_button.disabled = False\n",
    "    else:\n",
    "        progress_output7.value = \"<p style='color: red;'>\u274c Model training failed. Check the output for errors.</p>\"\n",
    "\n",
    "# Create buttons\n",
    "train_button = widgets.Button(\n",
    "    description='Train Model',\n",
    "    button_style='danger',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "export_button = widgets.Button(\n",
    "    description='Continue to Export',\n",
    "    button_style='success',\n",
    "    icon='arrow-right',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "# Connect buttons to functions\n",
    "train_button.on_click(train_model)\n",
    "\n",
    "# Display buttons\n",
    "button_box = widgets.HBox([train_button, export_button])\n",
    "display(button_box)\n",
    "display(progress_output7)\n",
    "\n",
    "# Add a note about training\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Training can take a long time, especially with many training steps. \"\n",
    "    \"The process may appear stuck for several minutes between updates. \"\n",
    "    \"This is normal - the training is still running in the background.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce4 Step 8: Export the Model\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Model Export</h3>\n",
    "    <p>The final step is to export the trained model for use on devices. The model is converted to TensorFlow Lite format and quantized to reduce its size and improve inference speed.</p>\n",
    "    <p>You'll also need to create a model manifest file to use with ESPHome. The manifest contains metadata about the model and detection parameters.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udce4 Export the trained model\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create a slider for detection threshold\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.1,\n",
    "    max=0.9,\n",
    "    step=0.05,\n",
    "    description='Detection Threshold:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the slider\n",
    "display(HTML(\"<h4>Model Export Settings</h4>\"))\n",
    "display(threshold_slider)\n",
    "\n",
    "# Progress output\n",
    "progress_output8 = widgets.HTML(value=\"\")\n",
    "\n",
    "# Function to export the model\n",
    "def export_model(button):\n",
    "    import shutil\n",
    "    \n",
    "    progress_output8.value = \"<p>Exporting model...</p>\"\n",
    "    \n",
    "    # Get the wake word and threshold\n",
    "    wake_word = wake_word_input.value\n",
    "    threshold = threshold_slider.value\n",
    "    \n",
    "    # Path to the trained model\n",
    "    model_path = \"trained_models/wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite\"\n",
    "    \n",
    "    # Check if the model exists\n",
    "    if not os.path.exists(model_path):\n",
    "        progress_output8.value = \"<p style='color: red;'>\u274c Model file not found. Make sure training completed successfully.</p>\"\n",
    "        return\n",
    "    \n",
    "    # Create export directory\n",
    "    export_dir = f\"exported_model_{wake_word}\"\n",
    "    if not os.path.exists(export_dir):\n",
    "        os.makedirs(export_dir)\n",
    "    \n",
    "    # Copy the model file\n",
    "    export_model_path = os.path.join(export_dir, f\"{wake_word}.tflite\")\n",
    "    shutil.copy(model_path, export_model_path)\n",
    "    \n",
    "    # Create manifest file\n",
    "    manifest = {\n",
    "        \"name\": wake_word,\n",
    "        \"version\": 2,\n",
    "        \"type\": \"micro_speech\",\n",
    "        \"description\": f\"Custom wake word model for '{wake_word}'\",\n",
    "        \"specs\": {\n",
    "            \"average_window_length\": 10,\n",
    "            \"detection_threshold\": threshold,\n",
    "            \"suppression_ms\": 1000,\n",
    "            \"minimum_count\": 3,\n",
    "            \"sample_rate\": 16000,\n",
    "            \"vocabulary\": [\"_silence_\", \"_unknown_\", wake_word]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save manifest file\n",
    "    manifest_path = os.path.join(export_dir, \"manifest.json\")\n",
    "    with open(manifest_path, 'w') as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    \n",
    "    # Create ESPHome configuration example\n",
    "    esphome_config = f\"\"\"\n",
    "# Wake word configuration\n",
    "micro_wake_word:\n",
    "  model_file: \"{os.path.basename(export_model_path)}\"\n",
    "  model_name: \"{wake_word}\"\n",
    "  probability_cutoff: {threshold}\n",
    "  \n",
    "binary_sensor:\n",
    "  - platform: micro_wake_word\n",
    "    name: \"Wake Word Detected\"\n",
    "    id: wake_word\n",
    "    model_id: {wake_word}\n",
    "    \n",
    "# Optional - add a text-to-speech response\n",
    "esphome:\n",
    "  on_boot:\n",
    "    priority: -100\n",
    "    then:\n",
    "      - delay: 5s\n",
    "      - logger.log: \"Wake word detection ready\"\n",
    "      \n",
    "on_wake_word:\n",
    "  - logger.log: \"Wake word detected!\"\n",
    "  # Add your actions here\n",
    "\"\"\"\n",
    "    \n",
    "    # Save ESPHome config example\n",
    "    config_path = os.path.join(export_dir, \"esphome_example.yaml\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(esphome_config)\n",
    "    \n",
    "    progress_output8.value = f\"<p style='color: green;'>\u2705 Model exported successfully to {export_dir}!</p>\"\n",
    "    progress_output8.value += f\"<p>Files created:</p>\"\n",
    "    progress_output8.value += f\"<ul>\"\n",
    "    progress_output8.value += f\"<li><b>{os.path.basename(export_model_path)}</b> - The TFLite model file</li>\"\n",
    "    progress_output8.value += f\"<li><b>manifest.json</b> - Model metadata for ESPHome</li>\"\n",
    "    progress_output8.value += f\"<li><b>esphome_example.yaml</b> - Example ESPHome configuration</li>\"\n",
    "    progress_output8.value += f\"</ul>\"\n",
    "    \n",
    "    progress_output8.value += f\"<p>Files are saved in the <code>{export_dir}</code> directory.</p>\"\n",
    "\n",
    "# Create export button\n",
    "export_button = widgets.Button(\n",
    "    description='Export Model',\n",
    "    button_style='primary',\n",
    "    icon='file-export'\n",
    ")\n",
    "\n",
    "# Connect button to function\n",
    "export_button.on_click(export_model)\n",
    "\n",
    "# Display button\n",
    "display(export_button)\n",
    "display(progress_output8)\n",
    "\n",
    "# Add a note about using the model\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #dff0d8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<h4 style='margin-top: 0;'>Using Your Model with ESPHome</h4>\"\n",
    "    \"<p>To use your trained model with ESPHome:</p>\"\n",
    "    \"<ol>\"\n",
    "    \"<li>Copy the .tflite file and manifest.json to your ESPHome configuration directory</li>\"\n",
    "    \"<li>Add the configuration from esphome_example.yaml to your device's YAML file</li>\"\n",
    "    \"<li>Adjust the detection threshold if needed (higher = fewer false positives, but may miss some activations)</li>\"\n",
    "    \"<li>Flash your device with the updated configuration</li>\"\n",
    "    \"</ol>\"\n",
    "    \"<p>For more information, see the <a href='https://esphome.io/components/micro_wake_word' target='_blank'>ESPHome documentation</a>.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Congratulations!\n",
    "\n",
    "<div style=\"background-color: #f0f7fb; padding: 15px; border-radius: 10px; border-left: 5px solid #3498db; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #3498db;\">You've Successfully Trained a Custom Wake Word Model!</h3>\n",
    "    <p>You've completed all the steps to train and export a custom wake word model using microWakeWord. Here's what you've accomplished:</p>\n",
    "    <ul>\n",
    "        <li>Generated synthetic wake word samples</li>\n",
    "        <li>Applied audio augmentation to improve robustness</li>\n",
    "        <li>Configured and trained a neural network model</li>\n",
    "        <li>Exported the model for use on devices</li>\n",
    "    </ul>\n",
    "    <p>If your model doesn't perform as expected, try experimenting with different settings:</p>\n",
    "    <ul>\n",
    "        <li>Try different phonetic spellings of your wake word</li>\n",
    "        <li>Adjust augmentation parameters</li>\n",
    "        <li>Increase training steps</li>\n",
    "        <li>Modify class weights</li>\n",
    "        <li>Try different model architectures</li>\n",
    "    </ul>\n",
    "    <p>Happy wake word detecting!</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}