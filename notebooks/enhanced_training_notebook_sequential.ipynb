{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11cNiLqvWC6"
   },
   "source": [
    "# üéØ Training a microWakeWord Model\n",
    "\n",
    "<div style=\"background-color: #f0f7fb; padding: 15px; border-radius: 10px; border-left: 5px solid #3498db; margin-bottom: 20px;\">\n",
    "    <h2 style=\"margin-top: 0; color: #3498db;\">Welcome to microWakeWord Training!</h2>\n",
    "    <p>This notebook guides you through training a custom wake word model using microWakeWord. It provides a <b>visual and interactive</b> approach while maintaining the powerful functionality of the basic training process.</p>\n",
    "    <p><b>Python 3.10</b> is recommended for the best experience.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #fff3cd; padding: 15px; border-radius: 10px; border-left: 5px solid #f0ad4e; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #8a6d3b;\">‚ö†Ô∏è Important Note</h3>\n",
    "    <p>The model generated will require experimentation to achieve good results. You may need to adjust various settings to get a model that:</p>\n",
    "    <ul>\n",
    "        <li>Reliably detects your wake word</li>\n",
    "        <li>Doesn't trigger falsely on similar sounds</li>\n",
    "        <li>Works well in your specific environment</li>\n",
    "    </ul>\n",
    "    <p>This notebook is designed to be run <b>sequentially</b>. Run each cell in order by pressing Shift+Enter.</p>\n",
    "</div>\n",
    "\n",
    "## üìã What You'll Learn\n",
    "\n",
    "1. How to set up the microWakeWord training environment\n",
    "2. How to generate and augment wake word samples\n",
    "3. How to train a custom wake word model\n",
    "4. How to evaluate and export your model for use on devices\n",
    "\n",
    "<div style=\"background-color: #dff0d8; padding: 15px; border-radius: 10px; border-left: 5px solid #5cb85c; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #3c763d;\">üí° Pro Tip</h3>\n",
    "    <p>Training is <b>much faster</b> on a local GPU. Make sure you have the necessary dependencies installed for GPU acceleration.</p>\n",
    "</div>\n",
    "\n",
    "At the end of this notebook, you'll have a TFLite model file ready for deployment on ESPHome devices. For deployment instructions, see the [ESPHome documentation](https://esphome.io/components/micro_wake_word) and [model examples](https://github.com/esphome/micro-wake-word-models/tree/main/models/v2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFf6511E65ff"
   },
   "outputs": [],
   "source": [
    "# üîß Setup: Install microWakeWord and dependencies\n",
    "# This cell installs all necessary packages for training\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Display a progress message\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #f8f9fa; padding: 10px; border-radius: 5px;'>\"\n",
    "    \"<h3 style='margin-top: 0;'>üì¶ Installing dependencies...</h3>\"\n",
    "    \"<p>This may take a few minutes. Please wait until completion.</p>\"\n",
    "    \"</div>\"\n",
    "))\n",
    "\n",
    "# Platform-specific installations\n",
    "if platform.system() == \"Darwin\":\n",
    "    # `pymicro-features` is installed from a fork to support building on macOS\n",
    "    !pip install 'git+https://github.com/puddly/pymicro-features@puddly/minimum-cpp-version'\n",
    "\n",
    "# `audio-metadata` is installed from a fork to unpin `attrs` from a version that breaks Jupyter\n",
    "!pip install 'git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f'\n",
    "\n",
    "# Install ipywidgets for interactive notebook elements\n",
    "!pip install ipywidgets tqdm matplotlib\n",
    "\n",
    "# Clone and install microWakeWord\n",
    "!git clone https://github.com/BigPappy098/microWakeWord\n",
    "!pip install -e ./microWakeWord\n",
    "\n",
    "# Display success message\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #dff0d8; padding: 10px; border-radius: 5px;'>\"\n",
    "    \"<h3 style='margin-top: 0; color: #3c763d;'>‚úÖ Setup Complete!</h3>\"\n",
    "    \"<p>All dependencies have been installed successfully.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé§ Step 1: Choose Your Wake Word\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">Selecting an Effective Wake Word</h3>\n",
    "    <p>A good wake word should be:</p>\n",
    "    <ul>\n",
    "        <li><b>Distinctive</b>: Unique sound patterns not common in everyday speech</li>\n",
    "        <li><b>Multi-syllabic</b>: 2-5 syllables work best (e.g., \"hey computer\", \"alexa\")</li>\n",
    "        <li><b>Clear pronunciation</b>: Avoid words that are difficult to pronounce consistently</li>\n",
    "    </ul>\n",
    "    <p>You can use phonetic spellings to improve recognition. For example, \"computer\" might be better as \"kuhm-pyoo-ter\".</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEluu7nL7ywd"
   },
   "outputs": [],
   "source": [
    "# üé§ Set your wake word and generate a sample to verify\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Audio, display, HTML\n",
    "\n",
    "# Create an interactive text input for the wake word\n",
    "wake_word_input = widgets.Text(\n",
    "    value='hey_computer',\n",
    "    description='Wake Word:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Help text\n",
    "help_text = widgets.HTML(\n",
    "    value=\"<p style='color: #666; font-style: italic;'>Use underscores instead of spaces (e.g., 'hey_computer'). Try phonetic spellings for better results.</p>\"\n",
    ")\n",
    "\n",
    "# Display the input widget\n",
    "display(wake_word_input)\n",
    "display(help_text)\n",
    "\n",
    "# Setup piper sample generator if not already done\n",
    "if not os.path.exists(\"./piper-sample-generator\"):\n",
    "    display(HTML(\"<p>Setting up sample generator...</p>\"))\n",
    "    \n",
    "    if platform.system() == \"Darwin\":\n",
    "        !git clone -b mps-support https://github.com/kahrendt/piper-sample-generator\n",
    "    else:\n",
    "        !git clone https://github.com/rhasspy/piper-sample-generator\n",
    "\n",
    "    !wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
    "\n",
    "    # Install system dependencies\n",
    "    !pip install torch torchaudio piper-phonemize-cross==1.2.1\n",
    "\n",
    "    if \"piper-sample-generator/\" not in sys.path:\n",
    "        sys.path.append(\"piper-sample-generator/\")\n",
    "        \n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(\"generated_samples\"):\n",
    "    os.makedirs(\"generated_samples\")\n",
    "\n",
    "# Generate a sample for the current wake word\n",
    "target_word = wake_word_input.value\n",
    "display(HTML(f\"<p>Generating sample for '{target_word}'...</p>\"))\n",
    "\n",
    "!python3 piper-sample-generator/generate_samples.py \"{target_word}\" \\\n",
    "--max-samples 1 \\\n",
    "--batch-size 1 \\\n",
    "--output-dir generated_samples\n",
    "\n",
    "# Display the audio\n",
    "display(HTML(\"<p style='color: green;'>‚úÖ Sample generated! Listen below:</p>\"))\n",
    "display(Audio(\"generated_samples/0.wav\", autoplay=True))\n",
    "\n",
    "# Add a note about changing the wake word\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> If you want to change the wake word, edit the text field above and run this cell again.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîä Step 2: Generate Training Samples\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Training Samples</h3>\n",
    "    <p>To train a robust model, we need many examples of our wake word. The sample generator creates synthetic speech samples with different voices and variations.</p>\n",
    "    <p>You can adjust the number of samples and batch size below. More samples generally lead to better models but take longer to generate.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SvGtCCM9akR"
   },
   "outputs": [],
   "source": [
    "# üîä Generate multiple wake word samples for training\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "\n",
    "# Create sliders for sample count and batch size\n",
    "sample_count_slider = widgets.IntSlider(\n",
    "    value=1000,\n",
    "    min=100,\n",
    "    max=5000,\n",
    "    step=100,\n",
    "    description='Sample Count:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "batch_size_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=10,\n",
    "    max=200,\n",
    "    step=10,\n",
    "    description='Batch Size:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the sliders\n",
    "display(sample_count_slider)\n",
    "display(batch_size_slider)\n",
    "\n",
    "# Add a note about adjusting settings\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Adjust the sliders above if needed, then run this cell to generate samples.</p>\"\n",
    "    \"</div>\"\n",
    "))\n",
    "\n",
    "# Generate the samples\n",
    "target_word = wake_word_input.value\n",
    "sample_count = sample_count_slider.value\n",
    "batch_size = batch_size_slider.value\n",
    "\n",
    "display(HTML(f\"<p>Generating {sample_count} samples with batch size {batch_size}...</p>\"))\n",
    "\n",
    "!python3 piper-sample-generator/generate_samples.py \"{target_word}\" \\\n",
    "--max-samples {sample_count} \\\n",
    "--batch-size {batch_size} \\\n",
    "--output-dir generated_samples\n",
    "\n",
    "# Count the generated files\n",
    "file_count = len(glob.glob('generated_samples/*.wav'))\n",
    "\n",
    "# Display success message\n",
    "display(HTML(f\"<p style='color: green;'>‚úÖ Generated {file_count} samples successfully!</p>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 3: Download Negative Samples\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Negative Samples</h3>\n",
    "    <p>To train a robust model, we need \"negative\" samples - audio that is NOT the wake word. These help the model learn what to ignore.</p>\n",
    "    <p>The pre-generated negative datasets include:</p>\n",
    "    <ul>\n",
    "        <li><b>Speech</b>: General speech samples</li>\n",
    "        <li><b>Dinner Party</b>: Conversational audio with multiple speakers</li>\n",
    "        <li><b>No Speech</b>: Environmental sounds without speech</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Download pre-generated negative datasets\n",
    "\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<p>Starting download of negative datasets...</p>\"))\n",
    "\n",
    "output_dir = './negative_datasets'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    link_root = \"https://huggingface.co/datasets/kahrendt/microwakeword/resolve/main/\"\n",
    "    filenames = ['dinner_party.zip', 'dinner_party_eval.zip', 'no_speech.zip', 'speech.zip']\n",
    "    \n",
    "    for i, fname in enumerate(filenames):\n",
    "        display(HTML(f\"<p>Downloading {fname} ({i+1}/{len(filenames)})...</p>\"))\n",
    "        link = link_root + fname\n",
    "        zip_path = f\"negative_datasets/{fname}\"\n",
    "        !wget -O {zip_path} {link}\n",
    "        \n",
    "        display(HTML(f\"<p>Extracting {fname}...</p>\"))\n",
    "        !unzip -q {zip_path} -d {output_dir}\n",
    "\n",
    "    display(HTML(\"<p style='color: green;'>‚úÖ All negative datasets downloaded and extracted successfully!</p>\"))\n",
    "else:\n",
    "    display(HTML(\"<p style='color: blue;'>‚ÑπÔ∏è Negative datasets already exist. Skipping download.</p>\"))\n",
    "\n",
    "# Add a note about the datasets\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> The negative datasets are essential for training a model that doesn't trigger on non-wake word sounds.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Step 4: Set Up Audio Augmentation\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Audio Augmentation</h3>\n",
    "    <p>Audio augmentation helps create more robust models by applying various transformations to our samples:</p>\n",
    "    <ul>\n",
    "        <li><b>Background Noise</b>: Adds realistic background sounds</li>\n",
    "        <li><b>Room Effects</b>: Simulates different acoustic environments</li>\n",
    "        <li><b>Audio Effects</b>: Applies distortion, EQ, and other modifications</li>\n",
    "    </ul>\n",
    "    <p>You can adjust the intensity of these effects using the controls below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Configure audio augmentation settings\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Audio\n",
    "\n",
    "# Create sliders for augmentation parameters\n",
    "background_prob_slider = widgets.FloatSlider(\n",
    "    value=0.75,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Background Noise:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "rir_prob_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Room Effects:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "effects_prob_slider = widgets.FloatSlider(\n",
    "    value=0.1,\n",
    "    min=0.0,\n",
    "    max=0.5,\n",
    "    step=0.05,\n",
    "    description='Audio Effects:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "snr_range_slider = widgets.IntRangeSlider(\n",
    "    value=[-5, 10],\n",
    "    min=-20,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='SNR Range (dB):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the sliders\n",
    "display(HTML(\"<h4>Augmentation Intensity Controls</h4>\"))\n",
    "display(background_prob_slider)\n",
    "display(rir_prob_slider)\n",
    "display(effects_prob_slider)\n",
    "display(snr_range_slider)\n",
    "\n",
    "# Add a note about adjusting settings\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Adjust the sliders above if needed, then run this cell to set up augmentation.</p>\"\n",
    "    \"</div>\"\n",
    "))\n",
    "\n",
    "# Set up augmentation\n",
    "from microwakeword.audio.augmentation import Augmentation\n",
    "from microwakeword.audio.clips import Clips\n",
    "\n",
    "display(HTML(\"<p>Setting up audio augmentation...</p>\"))\n",
    "\n",
    "# Get values from sliders\n",
    "bg_prob = background_prob_slider.value\n",
    "rir_prob = rir_prob_slider.value\n",
    "effect_prob = effects_prob_slider.value\n",
    "min_snr, max_snr = snr_range_slider.value\n",
    "\n",
    "# Set up clips and augmentation\n",
    "clips = Clips(input_directory='generated_samples',\n",
    "              file_pattern='*.wav',\n",
    "              max_clip_duration_s=None,\n",
    "              remove_silence=False,\n",
    "              random_split_seed=10,\n",
    "              split_count=0.1,\n",
    "              )\n",
    "\n",
    "augmenter = Augmentation(augmentation_duration_s=3.2,\n",
    "                         augmentation_probabilities = {\n",
    "                                \"SevenBandParametricEQ\": effect_prob,\n",
    "                                \"TanhDistortion\": effect_prob,\n",
    "                                \"PitchShift\": effect_prob,\n",
    "                                \"BandStopFilter\": effect_prob,\n",
    "                                \"AddColorNoise\": effect_prob,\n",
    "                                \"AddBackgroundNoise\": bg_prob,\n",
    "                                \"Gain\": 1.0,\n",
    "                                \"RIR\": rir_prob,\n",
    "                            },\n",
    "                         impulse_paths = ['mit_rirs'],\n",
    "                         background_paths = ['fma_16k', 'audioset_16k'],\n",
    "                         background_min_snr_db = min_snr,\n",
    "                         background_max_snr_db = max_snr,\n",
    "                         min_jitter_s = 0.195,\n",
    "                         max_jitter_s = 0.205,\n",
    "                         )\n",
    "\n",
    "display(HTML(\"<p style='color: green;'>‚úÖ Audio augmentation configured successfully!</p>\"))\n",
    "\n",
    "# Generate a preview\n",
    "display(HTML(\"<p>Generating augmented preview...</p>\"))\n",
    "from microwakeword.audio.audio_utils import save_clip\n",
    "\n",
    "# Get a random clip and augment it\n",
    "random_clip = clips.get_random_clip()\n",
    "augmented_clip = augmenter.augment_clip(random_clip)\n",
    "save_clip(augmented_clip, 'augmented_preview.wav')\n",
    "\n",
    "display(HTML(\"<p style='color: green;'>‚úÖ Preview generated! Listen below:</p>\"))\n",
    "display(Audio(\"augmented_preview.wav\", autoplay=True))\n",
    "\n",
    "# Add a note about augmentation\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #dff0d8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Tip:</b> Experiment with different augmentation settings to improve model robustness. \"\n",
    "    \"Higher values create more challenging training data but may make training more difficult.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 5: Generate Augmented Features\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Feature Generation</h3>\n",
    "    <p>In this step, we'll generate spectrograms from our augmented audio samples. These spectrograms will be used to train the neural network.</p>\n",
    "    <p>We'll create three sets of data:</p>\n",
    "    <ul>\n",
    "        <li><b>Training</b>: Used to train the model</li>\n",
    "        <li><b>Validation</b>: Used to evaluate the model during training</li>\n",
    "        <li><b>Testing</b>: Used for final evaluation</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Generate augmented features for training, validation, and testing\n",
    "\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "display(HTML(\"<p>Starting feature generation...</p>\"))\n",
    "\n",
    "output_dir = 'generated_augmented_features'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "from microwakeword.audio.spectrograms import SpectrogramGeneration\n",
    "from mmap_ninja.ragged import RaggedMmap\n",
    "\n",
    "splits = [\"training\", \"validation\", \"testing\"]\n",
    "for i, split in enumerate(splits):\n",
    "    display(HTML(f\"<p>Processing {split} set ({i+1}/{len(splits)})...</p>\"))\n",
    "    \n",
    "    out_dir = os.path.join(output_dir, split)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    split_name = \"train\"\n",
    "    repetition = 2\n",
    "    \n",
    "    spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                       augmenter=augmenter,\n",
    "                                       slide_frames=10,\n",
    "                                       step_ms=10,\n",
    "                                       )\n",
    "    \n",
    "    if split == \"validation\":\n",
    "        split_name = \"validation\"\n",
    "        repetition = 1\n",
    "    elif split == \"testing\":\n",
    "        split_name = \"test\"\n",
    "        repetition = 1\n",
    "        spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                           augmenter=augmenter,\n",
    "                                           slide_frames=1,\n",
    "                                           step_ms=10,\n",
    "                                           )\n",
    "    \n",
    "    display(HTML(f\"<p>Generating spectrograms for {split} set...</p>\"))\n",
    "    \n",
    "    RaggedMmap.from_generator(\n",
    "        out_dir=os.path.join(out_dir, 'wakeword_mmap'),\n",
    "        sample_generator=spectrograms.spectrogram_generator(split=split_name, repeat=repetition),\n",
    "        batch_size=100,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "display(HTML(\"<p style='color: green;'>‚úÖ All features generated successfully!</p>\"))\n",
    "\n",
    "# Add a note about feature generation\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Feature generation may take several minutes depending on your hardware. \"\n",
    "    \"These spectrograms will be used to train the neural network model.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 6: Configure Training Parameters\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Training Configuration</h3>\n",
    "    <p>The training configuration controls how the model learns from our data. Key parameters include:</p>\n",
    "    <ul>\n",
    "        <li><b>Training Steps</b>: How long to train the model</li>\n",
    "        <li><b>Batch Size</b>: How many samples to process at once</li>\n",
    "        <li><b>Class Weights</b>: How to balance positive and negative examples</li>\n",
    "        <li><b>Learning Rate</b>: How quickly the model adapts to the training data</li>\n",
    "    </ul>\n",
    "    <p>Adjust these parameters to find the optimal balance for your wake word.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Configure training parameters\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Create sliders for training parameters\n",
    "training_steps_slider = widgets.IntSlider(\n",
    "    value=10000,\n",
    "    min=5000,\n",
    "    max=30000,\n",
    "    step=1000,\n",
    "    description='Training Steps:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "batch_size_slider = widgets.IntSlider(\n",
    "    value=128,\n",
    "    min=32,\n",
    "    max=256,\n",
    "    step=32,\n",
    "    description='Batch Size:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "negative_weight_slider = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=5,\n",
    "    max=50,\n",
    "    step=5,\n",
    "    description='Negative Class Weight:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "learning_rate_slider = widgets.FloatLogSlider(\n",
    "    value=0.001,\n",
    "    base=10,\n",
    "    min=-4,  # 10^-4 = 0.0001\n",
    "    max=-2,  # 10^-2 = 0.01\n",
    "    step=0.1,\n",
    "    description='Learning Rate:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the sliders\n",
    "display(HTML(\"<h4>Training Parameters</h4>\"))\n",
    "display(training_steps_slider)\n",
    "display(batch_size_slider)\n",
    "display(negative_weight_slider)\n",
    "display(learning_rate_slider)\n",
    "\n",
    "# Add a note about adjusting settings\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Adjust the sliders above if needed, then run this cell to create the training configuration.</p>\"\n",
    "    \"</div>\"\n",
    "))\n",
    "\n",
    "# Create configuration\n",
    "display(HTML(\"<p>Creating training configuration...</p>\"))\n",
    "\n",
    "# Get values from sliders\n",
    "training_steps = training_steps_slider.value\n",
    "batch_size = batch_size_slider.value\n",
    "negative_weight = negative_weight_slider.value\n",
    "learning_rate = learning_rate_slider.value\n",
    "\n",
    "# Create configuration dictionary\n",
    "config = {}\n",
    "\n",
    "config[\"window_step_ms\"] = 10\n",
    "config[\"train_dir\"] = \"trained_models/wakeword\"\n",
    "\n",
    "# Configure feature directories\n",
    "config[\"features\"] = [\n",
    "    {\n",
    "        \"features_dir\": \"generated_augmented_features\",\n",
    "        \"sampling_weight\": 2.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": True,\n",
    "        \"truncation_strategy\": \"truncate_start\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"negative_datasets/speech\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"negative_datasets/dinner_party\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"negative_datasets/no_speech\",\n",
    "        \"sampling_weight\": 5.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    { # Only used for validation and testing\n",
    "        \"features_dir\": \"negative_datasets/dinner_party_eval\",\n",
    "        \"sampling_weight\": 0.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"split\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Training parameters\n",
    "config[\"training_steps\"] = [training_steps]\n",
    "config[\"positive_class_weight\"] = [1]\n",
    "config[\"negative_class_weight\"] = [negative_weight]\n",
    "config[\"learning_rates\"] = [learning_rate]\n",
    "config[\"batch_size\"] = batch_size\n",
    "\n",
    "# SpecAugment parameters (disabled by default)\n",
    "config[\"time_mask_max_size\"] = [0]\n",
    "config[\"time_mask_count\"] = [0]\n",
    "config[\"freq_mask_max_size\"] = [0]\n",
    "config[\"freq_mask_count\"] = [0]\n",
    "\n",
    "# Evaluation parameters\n",
    "config[\"eval_step_interval\"] = 500\n",
    "config[\"clip_duration_ms\"] = 1500\n",
    "\n",
    "# Model selection criteria\n",
    "config[\"target_minimization\"] = 0.9\n",
    "config[\"minimization_metric\"] = None\n",
    "config[\"maximization_metric\"] = \"average_viable_recall\"\n",
    "\n",
    "# Save configuration to file\n",
    "with open(os.path.join(\"training_parameters.yaml\"), \"w\") as file:\n",
    "    yaml.dump(config, file)\n",
    "\n",
    "display(HTML(\"<p style='color: green;'>‚úÖ Training configuration created successfully!</p>\"))\n",
    "\n",
    "# Add a note about configuration\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #dff0d8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Tip:</b> For most wake words, the default settings work well as a starting point. \"\n",
    "    \"If your model doesn't perform well, try adjusting these parameters:</p>\"\n",
    "    \"<ul>\"\n",
    "    \"<li>Increase <b>Training Steps</b> for better accuracy (but longer training time)</li>\"\n",
    "    \"<li>Increase <b>Negative Class Weight</b> to reduce false positives</li>\"\n",
    "    \"<li>Decrease <b>Negative Class Weight</b> if the model rarely detects the wake word</li>\"\n",
    "    \"</ul>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: Train the Model\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Model Training</h3>\n",
    "    <p>Now we'll train the neural network model using the configuration we created. The training process:</p>\n",
    "    <ul>\n",
    "        <li>Feeds batches of spectrograms to the neural network</li>\n",
    "        <li>Adjusts the model weights based on prediction errors</li>\n",
    "        <li>Periodically evaluates the model on validation data</li>\n",
    "        <li>Saves the best-performing model weights</li>\n",
    "    </ul>\n",
    "    <p>Training may take several minutes to hours depending on your hardware and the number of training steps.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Train the wake word model\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Create model architecture selection dropdown\n",
    "model_architecture = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('MixedNet (Recommended)', 'mixednet'),\n",
    "        ('MobileNet', 'mobilenet'),\n",
    "        ('ResNet', 'resnet')\n",
    "    ],\n",
    "    value='mixednet',\n",
    "    description='Model Architecture:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Create model size selection dropdown\n",
    "model_size = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Small', 'small'),\n",
    "        ('Medium (Recommended)', 'medium'),\n",
    "        ('Large', 'large')\n",
    "    ],\n",
    "    value='medium',\n",
    "    description='Model Size:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the dropdowns\n",
    "display(HTML(\"<h4>Model Architecture Settings</h4>\"))\n",
    "display(model_architecture)\n",
    "display(model_size)\n",
    "\n",
    "# Add a note about adjusting settings\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Adjust the model architecture and size if needed, then run this cell to train the model.</p>\"\n",
    "    \"</div>\"\n",
    "))\n",
    "\n",
    "# Get selected architecture and size\n",
    "arch = model_architecture.value\n",
    "size = model_size.value\n",
    "\n",
    "display(HTML(f\"<p>Starting model training with {arch} architecture ({size} size)...</p>\"))\n",
    "display(HTML(\"<p>This may take a while. Please be patient.</p>\"))\n",
    "\n",
    "# Define architecture parameters based on size\n",
    "if arch == 'mixednet':\n",
    "    if size == 'small':\n",
    "        pointwise_filters = \"48,48,48,48\"\n",
    "        kernel_sizes = \"'[5],[7,11],[9,15],[17]'\"\n",
    "        first_conv_filters = 24\n",
    "    elif size == 'medium':\n",
    "        pointwise_filters = \"64,64,64,64\"\n",
    "        kernel_sizes = \"'[5],[7,11],[9,15],[23]'\"\n",
    "        first_conv_filters = 32\n",
    "    else:  # large\n",
    "        pointwise_filters = \"96,96,96,96\"\n",
    "        kernel_sizes = \"'[5],[7,11],[9,15],[23]'\"\n",
    "        first_conv_filters = 48\n",
    "        \n",
    "    # Build the command\n",
    "    cmd = f\"python -m microwakeword.model_train_eval \\\n",
    "    --training_config='training_parameters.yaml' \\\n",
    "    --train 1 \\\n",
    "    --restore_checkpoint 1 \\\n",
    "    --test_tf_nonstreaming 0 \\\n",
    "    --test_tflite_nonstreaming 0 \\\n",
    "    --test_tflite_nonstreaming_quantized 0 \\\n",
    "    --test_tflite_streaming 0 \\\n",
    "    --test_tflite_streaming_quantized 1 \\\n",
    "    --use_weights \\\"best_weights\\\" \\\n",
    "    mixednet \\\n",
    "    --pointwise_filters \\\"{pointwise_filters}\\\" \\\n",
    "    --repeat_in_block \\\"1,1,1,1\\\" \\\n",
    "    --mixconv_kernel_sizes {kernel_sizes} \\\n",
    "    --residual_connection \\\"0,0,0,0\\\" \\\n",
    "    --first_conv_filters {first_conv_filters} \\\n",
    "    --first_conv_kernel_size 5 \\\n",
    "    --stride 3\"\n",
    "else:\n",
    "    # Simplified command for other architectures\n",
    "    cmd = f\"python -m microwakeword.model_train_eval \\\n",
    "    --training_config='training_parameters.yaml' \\\n",
    "    --train 1 \\\n",
    "    --restore_checkpoint 1 \\\n",
    "    --test_tf_nonstreaming 0 \\\n",
    "    --test_tflite_nonstreaming 0 \\\n",
    "    --test_tflite_nonstreaming_quantized 0 \\\n",
    "    --test_tflite_streaming 0 \\\n",
    "    --test_tflite_streaming_quantized 1 \\\n",
    "    --use_weights \\\"best_weights\\\" \\\n",
    "    {arch}\"\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Training:',\n",
    "    bar_style='info',\n",
    "    orientation='horizontal'\n",
    ")\n",
    "display(progress_bar)\n",
    "\n",
    "# Process output\n",
    "output_text = widgets.Output()\n",
    "display(output_text)\n",
    "\n",
    "# Run the command\n",
    "process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "\n",
    "with output_text:\n",
    "    for line in process.stdout:\n",
    "        print(line.strip())\n",
    "        if \"step\" in line and \"loss\" in line:\n",
    "            try:\n",
    "                # Extract step number and update progress\n",
    "                step_str = line.split(\"step\")[1].split(\",\")[0].strip()\n",
    "                step = int(step_str)\n",
    "                training_steps = training_steps_slider.value\n",
    "                progress = min(100, int(step * 100 / training_steps))\n",
    "                progress_bar.value = progress\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Wait for process to complete\n",
    "process.wait()\n",
    "\n",
    "if process.returncode == 0:\n",
    "    display(HTML(\"<p style='color: green;'>‚úÖ Model training completed successfully!</p>\"))\n",
    "else:\n",
    "    display(HTML(\"<p style='color: red;'>‚ùå Model training failed. Check the output for errors.</p>\"))\n",
    "\n",
    "# Add a note about training\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Training can take a long time, especially with many training steps. \"\n",
    "    \"The process may appear stuck for several minutes between updates. \"\n",
    "    \"This is normal - the training is still running in the background.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ Step 8: Export the Model\n",
    "\n",
    "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #2980b9;\">About Model Export</h3>\n",
    "    <p>The final step is to export the trained model for use on devices. The model is converted to TensorFlow Lite format and quantized to reduce its size and improve inference speed.</p>\n",
    "    <p>You'll also need to create a model manifest file to use with ESPHome. The manifest contains metadata about the model and detection parameters.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì§ Export the trained model\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create a slider for detection threshold\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.1,\n",
    "    max=0.9,\n",
    "    step=0.05,\n",
    "    description='Detection Threshold:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Display the slider\n",
    "display(HTML(\"<h4>Model Export Settings</h4>\"))\n",
    "display(threshold_slider)\n",
    "\n",
    "# Add a note about adjusting settings\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #fcf8e3; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<p><b>Note:</b> Adjust the detection threshold if needed, then run this cell to export the model.</p>\"\n",
    "    \"</div>\"\n",
    "))\n",
    "\n",
    "display(HTML(\"<p>Exporting model...</p>\"))\n",
    "\n",
    "# Get the wake word and threshold\n",
    "wake_word = wake_word_input.value\n",
    "threshold = threshold_slider.value\n",
    "\n",
    "# Path to the trained model\n",
    "model_path = \"trained_models/wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite\"\n",
    "\n",
    "# Check if the model exists\n",
    "if not os.path.exists(model_path):\n",
    "    display(HTML(\"<p style='color: red;'>‚ùå Model file not found. Make sure training completed successfully.</p>\"))\n",
    "else:\n",
    "    # Create export directory\n",
    "    export_dir = f\"exported_model_{wake_word}\"\n",
    "    if not os.path.exists(export_dir):\n",
    "        os.makedirs(export_dir)\n",
    "    \n",
    "    # Copy the model file\n",
    "    export_model_path = os.path.join(export_dir, f\"{wake_word}.tflite\")\n",
    "    shutil.copy(model_path, export_model_path)\n",
    "    \n",
    "    # Create manifest file\n",
    "    manifest = {\n",
    "        \"name\": wake_word,\n",
    "        \"version\": 2,\n",
    "        \"type\": \"micro_speech\",\n",
    "        \"description\": f\"Custom wake word model for '{wake_word}'\",\n",
    "        \"specs\": {\n",
    "            \"average_window_length\": 10,\n",
    "            \"detection_threshold\": threshold,\n",
    "            \"suppression_ms\": 1000,\n",
    "            \"minimum_count\": 3,\n",
    "            \"sample_rate\": 16000,\n",
    "            \"vocabulary\": [\"_silence_\", \"_unknown_\", wake_word]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save manifest file\n",
    "    manifest_path = os.path.join(export_dir, \"manifest.json\")\n",
    "    with open(manifest_path, 'w') as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    \n",
    "    # Create ESPHome configuration example\n",
    "    esphome_config = f\"\"\"\n",
    "# Wake word configuration\n",
    "micro_wake_word:\n",
    "  model_file: \"{os.path.basename(export_model_path)}\"\n",
    "  model_name: \"{wake_word}\"\n",
    "  probability_cutoff: {threshold}\n",
    "  \n",
    "binary_sensor:\n",
    "  - platform: micro_wake_word\n",
    "    name: \"Wake Word Detected\"\n",
    "    id: wake_word\n",
    "    model_id: {wake_word}\n",
    "    \n",
    "# Optional - add a text-to-speech response\n",
    "esphome:\n",
    "  on_boot:\n",
    "    priority: -100\n",
    "    then:\n",
    "      - delay: 5s\n",
    "      - logger.log: \"Wake word detection ready\"\n",
    "      \n",
    "on_wake_word:\n",
    "  - logger.log: \"Wake word detected!\"\n",
    "  # Add your actions here\n",
    "\"\"\"\n",
    "    \n",
    "    # Save ESPHome config example\n",
    "    config_path = os.path.join(export_dir, \"esphome_example.yaml\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(esphome_config)\n",
    "    \n",
    "    display(HTML(f\"<p style='color: green;'>‚úÖ Model exported successfully to {export_dir}!</p>\"))\n",
    "    display(HTML(f\"<p>Files created:</p>\"))\n",
    "    display(HTML(f\"<ul>\"))\n",
    "    display(HTML(f\"<li><b>{os.path.basename(export_model_path)}</b> - The TFLite model file</li>\"))\n",
    "    display(HTML(f\"<li><b>manifest.json</b> - Model metadata for ESPHome</li>\"))\n",
    "    display(HTML(f\"<li><b>esphome_example.yaml</b> - Example ESPHome configuration</li>\"))\n",
    "    display(HTML(f\"</ul>\"))\n",
    "    \n",
    "    display(HTML(f\"<p>Files are saved in the <code>{export_dir}</code> directory.</p>\"))\n",
    "\n",
    "# Add a note about using the model\n",
    "display(HTML(\n",
    "    \"<div style='background-color: #dff0d8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\"\n",
    "    \"<h4 style='margin-top: 0;'>Using Your Model with ESPHome</h4>\"\n",
    "    \"<p>To use your trained model with ESPHome:</p>\"\n",
    "    \"<ol>\"\n",
    "    \"<li>Copy the .tflite file and manifest.json to your ESPHome configuration directory</li>\"\n",
    "    \"<li>Add the configuration from esphome_example.yaml to your device's YAML file</li>\"\n",
    "    \"<li>Adjust the detection threshold if needed (higher = fewer false positives, but may miss some activations)</li>\"\n",
    "    \"<li>Flash your device with the updated configuration</li>\"\n",
    "    \"</ol>\"\n",
    "    \"<p>For more information, see the <a href='https://esphome.io/components/micro_wake_word' target='_blank'>ESPHome documentation</a>.</p>\"\n",
    "    \"</div>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "<div style=\"background-color: #f0f7fb; padding: 15px; border-radius: 10px; border-left: 5px solid #3498db; margin-bottom: 20px;\">\n",
    "    <h3 style=\"margin-top: 0; color: #3498db;\">You've Successfully Trained a Custom Wake Word Model!</h3>\n",
    "    <p>You've completed all the steps to train and export a custom wake word model using microWakeWord. Here's what you've accomplished:</p>\n",
    "    <ul>\n",
    "        <li>Generated synthetic wake word samples</li>\n",
    "        <li>Applied audio augmentation to improve robustness</li>\n",
    "        <li>Configured and trained a neural network model</li>\n",
    "        <li>Exported the model for use on devices</li>\n",
    "    </ul>\n",
    "    <p>If your model doesn't perform as expected, try experimenting with different settings:</p>\n",
    "    <ul>\n",
    "        <li>Try different phonetic spellings of your wake word</li>\n",
    "        <li>Adjust augmentation parameters</li>\n",
    "        <li>Increase training steps</li>\n",
    "        <li>Modify class weights</li>\n",
    "        <li>Try different model architectures</li>\n",
    "    </ul>\n",
    "    <p>Happy wake word detecting!</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
